{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.8 s, sys: 4.75 s, total: 44.5 s\n",
      "Wall time: 44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import json\n",
    "reviews = []\n",
    "with open(\"yelp_academic_dataset_review.json\") as f:\n",
    "    for line in f:\n",
    "        reviews.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'stars': 5, 'funny': 0, 'useful': 0, 'review_id': 'NxL8SIC5yqOdnlXCg18IBg', 'business_id': '2aFiy99vNLklCx3T_tGS9A', 'user_id': 'KpkOkG6RIf4Ra25Lhhxf1A', 'type': 'review', 'text': \"If you enjoy service by someone who is as competent as he is personable, I would recommend Corey Kaplan highly. The time he has spent here has been very productive and working with him educational and enjoyable. I hope not to need him again (though this is highly unlikely) but knowing he is there if I do is very nice. By the way, I'm not from El Centro, CA. but Scottsdale, AZ.\", 'date': '2011-10-10', 'cool': 0}\n"
     ]
    }
   ],
   "source": [
    "print(reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "prolific_reviewers = Counter([review['user_id'] for review in reviews]).most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_ids = {pr[0] : 0 for pr in prolific_reviewers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "by_author = {} # author : \"review 1\\n review 2\\n review 3\"\n",
    "for review in reviews:\n",
    "    uid = review['user_id']\n",
    "    if uid in keep_ids:\n",
    "        uid = review['user_id']\n",
    "        if uid in by_author:\n",
    "            by_author[uid] += \"\\n{}\".format(review['text'])\n",
    "        else:\n",
    "            by_author[uid] = \"{}\".format(review['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(by_author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(276136, 'ffPY_bHX8vLebHu8LBEqfg'),\n",
       " (278427, 'PeLGa5vUR8_mcsn-fn42Jg'),\n",
       " (351311, 'cMEtAiW60I5wE_vLfTxoJQ'),\n",
       " (370129, 'iDlkZO2iILS8Jwfdy7DP9A'),\n",
       " (461333, 'dt9IHwfuZs9D9LOH7gjNew')]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that we have at least 200000 characters for each author\n",
    "sorted([(len(by_author[key]), key) for key in by_author])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_chunks(l, n):\n",
    "    n = max(1, n)\n",
    "    return [l[i:i+n] for i in range(0, len(l), n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_texts = []  # the first 100 000 chars from each author\n",
    "train_labels = [] # each author\n",
    "test_texts = []   # 100 texts of 1000 characters each (second 100 000 chars of each author)\n",
    "test_labels = []  # each author * 100\n",
    "\n",
    "author_int = {author: i for i,author in enumerate(by_author)}\n",
    "int_author = {author_int[author]: author for author in author_int}\n",
    "\n",
    "for author in by_author:\n",
    "    train_text = by_author[author][:50000]\n",
    "    train_label = author_int[author]\n",
    "    train_texts.append(train_text)\n",
    "    train_labels.append(train_label)\n",
    "    \n",
    "    short_texts = get_chunks(by_author[author][50000:100000], 1000)\n",
    "    for text in short_texts:\n",
    "        test_texts.append(text)\n",
    "        test_labels.append(author_int[author])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 1500\n"
     ]
    }
   ],
   "source": [
    "print(len(train_texts), len(test_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vectorization - chars to ints\n",
    "import string\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    \"\"\"Sample predictions from a probability array\"\"\"\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds + 1e-6) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def generate(model, diversity=0.5, text=\"\"):\n",
    "    \"\"\"Generate text from a model\"\"\"\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "\n",
    "    for i in range(5000):\n",
    "        x = np.zeros((1, maxlen), dtype=np.int)\n",
    "        for t, char in enumerate(sentence):\n",
    "            try:\n",
    "                x[0, t] = char_indices[char]\n",
    "            except:\n",
    "                print(sentence)\n",
    "        preds = model.predict(x, verbose=0)[0][0]\n",
    "        next_index = sample(preds, diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    return\n",
    "\n",
    "def vectorize(text):\n",
    "    \"\"\"Convert text into character sequences\"\"\"\n",
    "    step = 3\n",
    "    sentences = []\n",
    "    next_chars = []\n",
    "    for i in range(0, len(text) - maxlen, step):\n",
    "        sentences.append(text[i: i + maxlen])\n",
    "        next_chars.append(text[i + maxlen])\n",
    "    X = np.zeros((len(sentences), maxlen), dtype=np.int)\n",
    "    y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for t, char in enumerate(sentence):\n",
    "            X[i, t] = char_indices[char]\n",
    "        y[i, char_indices[next_chars[i]]] = 1\n",
    "    return X, y\n",
    "\n",
    "def clean_text(text, charset):\n",
    "    text = \" \".join(text.split())  # all white space is one space\n",
    "    text = \"\".join([x for x in text if x in charset])  # remove characters that we don't care about\n",
    "    return text\n",
    "\n",
    "def get_model(modelfile, freeze=False):\n",
    "    model = load_model(modelfile)\n",
    "    if freeze:\n",
    "        for layer in model.layers[:-5]:\n",
    "            layer.trainable = False\n",
    "    return model\n",
    "\n",
    "chars = \" \" + string.ascii_letters + string.punctuation  # sorted to keep indices consistent\n",
    "charset = set(chars)  # for lookup\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "maxlen = 100  # must match length which generated model - the sequence length\n",
    "\n",
    "# load a pretrained language model\n",
    "modelfile = \"charlm2/model_middlemarch_cnn.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test train an author specific model\n",
    "test_author_text = clean_text(train_texts[0], charset)\n",
    "test_author_model = get_model(modelfile, freeze=True)\n",
    "X, y = vectorize(test_author_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"item. They were very tender, fall off the bone, and flavorful. The green chili potato was ok, but really not as special as I would expect for a restaurant's signature item. It is essentially a twice baked potato, but instead of putting the potato innards back into the potato skin, they stuff it into a pepper.... I thought the pepper was too firm and the flavors didn't completely complement each other. The filling could have been seasoned better. The sliders were alright, they were like little french dips sort of with chilies on top. I didn't love them, they just weren't that flavorful or special. The worst dish of the night was the tostadas... they lacked flavor, fell apart, and just were boring. When a menu states that when you order chilies, you're responsible for the heat level, I expect something will be spicy... but nothing was. I liked this place alright overall, but it was a bit inconsistent. I would probably come back for happy hour, but it wouldn't be my first choice in town.\\n\""
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_author_model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14929 samples, validate on 1659 samples\n",
      "Epoch 1/10\n",
      "14929/14929 [==============================] - 12s - loss: 4.3390 - main_out_loss: 2.1570 - aux_out_loss: 2.1820 - val_loss: 3.8408 - val_main_out_loss: 1.8432 - val_aux_out_loss: 1.9976\n",
      "Epoch 2/10\n",
      "14929/14929 [==============================] - 10s - loss: 4.1144 - main_out_loss: 2.0119 - aux_out_loss: 2.1025 - val_loss: 3.7507 - val_main_out_loss: 1.7889 - val_aux_out_loss: 1.9619\n",
      "Epoch 3/10\n",
      "14929/14929 [==============================] - 10s - loss: 3.9888 - main_out_loss: 1.9290 - aux_out_loss: 2.0598 - val_loss: 3.7181 - val_main_out_loss: 1.7673 - val_aux_out_loss: 1.9508\n",
      "Epoch 4/10\n",
      "14929/14929 [==============================] - 10s - loss: 3.8903 - main_out_loss: 1.8674 - aux_out_loss: 2.0230 - val_loss: 3.6922 - val_main_out_loss: 1.7519 - val_aux_out_loss: 1.9403\n",
      "Epoch 5/10\n",
      "14929/14929 [==============================] - 10s - loss: 3.8253 - main_out_loss: 1.8237 - aux_out_loss: 2.0016 - val_loss: 3.6625 - val_main_out_loss: 1.7316 - val_aux_out_loss: 1.9308\n",
      "Epoch 6/10\n",
      "14929/14929 [==============================] - 10s - loss: 3.7628 - main_out_loss: 1.7853 - aux_out_loss: 1.9775 - val_loss: 3.6595 - val_main_out_loss: 1.7299 - val_aux_out_loss: 1.9296\n",
      "Epoch 7/10\n",
      "14929/14929 [==============================] - 10s - loss: 3.7169 - main_out_loss: 1.7598 - aux_out_loss: 1.9571 - val_loss: 3.6527 - val_main_out_loss: 1.7253 - val_aux_out_loss: 1.9274\n",
      "Epoch 8/10\n",
      "14929/14929 [==============================] - 10s - loss: 3.6708 - main_out_loss: 1.7276 - aux_out_loss: 1.9432 - val_loss: 3.6325 - val_main_out_loss: 1.7088 - val_aux_out_loss: 1.9238\n",
      "Epoch 9/10\n",
      "14929/14929 [==============================] - 10s - loss: 3.6344 - main_out_loss: 1.7087 - aux_out_loss: 1.9257 - val_loss: 3.6371 - val_main_out_loss: 1.7126 - val_aux_out_loss: 1.9245\n",
      "Epoch 10/10\n",
      "14929/14929 [==============================] - 10s - loss: 3.6032 - main_out_loss: 1.6887 - aux_out_loss: 1.9145 - val_loss: 3.6250 - val_main_out_loss: 1.7062 - val_aux_out_loss: 1.9189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f74377b1c50>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that we don't overfit on 10 epochs\n",
    "test_author_model.fit(X, [y, y], epochs=10, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/288 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "285/285 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "288/294 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for text in test_texts[:100]:\n",
    "    X, y = vectorize(clean_text(text, charset))\n",
    "    score = test_author_model.evaluate(X, [y, y])\n",
    "    scores.append(score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.80500852288\n",
      "5.88146182806\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "\n",
    "print(mean(scores[:50]))\n",
    "print(mean(scores[50:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f74376ee9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(get_chunks(scores, 50)[:20]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.1628624592851473,\n",
       " 2.1628624592851473,\n",
       " 2.1628624592851473,\n",
       " 2.1628624592851473,\n",
       " 2.1628624592851473,\n",
       " 2.1628624592851473,\n",
       " 2.1628624592851473,\n",
       " 2.1628624592851473,\n",
       " 2.1628624592851473,\n",
       " 2.1628624592851473]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Generating with seed: \"does it really matter what it says this is some test text does it really matter what it says this is\"\n",
      "does it really matter what it says this is some test text does it really matter what it says this is the superior for breakfast from the staby and the consect was an instant something which was strength and the stabbit was the fact of the same start, which was stead of the same so those the flaos, was started and did not the sing which was something to be a little than the profese and the shock had been a little thing it was the constant that would be a little was stayful and got the means that which was staying the too streak in the new difficult in a strike and she had been distingun is a rash strength and the social distakes busina the fact the side of the same stands in the satisfactory was intention that she was great the side of the stick pocket (the sin had the state of the sub lady in the sat at the same time (lower because they were the same that was the state of the subdect on the satisfactory at the suble and the stabble as they carried (a fortunata past he was disgracated. The sun had the definity and the start. The se either solod (the distakaes had the fellow was the protres (ling her the stands which was not this subce of the burlodgas. It was large to be straged to the in anong the same shipt was sharped and complicatles chaplelenat's. I had redaid the child this place with the same start. The chucke something that the should childre before the sad was an excellent little of the sublic and had the food of the state of the same sort of the chick was strength than the choose (for the fact of the soot of the chaple was steaf the same stacking the same time (frid with a look and the best the same very his stupious that she had chosen the best the manusattic was rather and an interest some and the side of the better than the child the chice of the food of the best the rest and and he had the state of the side of the same shadowedraber that sort of the cottages and the same sand it was not the sense (was writing and the state of the short and judge social and got to those line the same time (it will be the same time (it su pttecis and be a little line the same that the same that I can do throw it as large to the to the stick and the spirity which was make the stabys chill tears (in the dest of a brill (the same study that of the should be the chief proceet was the floor and the scent the chipp in the chueful potien with any cast of the supposed (the ise is likely thing that any an answer than that the should have thought of the chief good and the end it was a good and servicted and a proof flavor ((ill I genery the subded but the professions that it was really who had the chief grace which was large image struggle and should be a little was starmed (a freed on the probracy in the state of the sat in the best the food of the summerhes and the state for the sake of the act comparison to the same sort of great so stand the distakase and an action that the swudt (all slip with the to go and the chicl (the hand this was the pater on the fact which I had the pleasures of the same so that the super that she was so change for a little shall go to sot and probably have to be satisfying the next day the sliep. The sat is a good creature and imperseverd it was rather than the spoke (and the sub had knee that she was stick the sup of a creep, but the sake of the side of the chief the rinute of the best the shadows which was something that the house (trebtrus or the same stands in the best the message of the same so that the chaple was still and dread and the simple state and she was strength and decided and like (a freedom with the same that the side of the people was started in the stady (I am sure I have the same that was the distant of the same start, but not did not the child the rest of the chief prepared food the same time (a chocke with the proud of the child the sand in the sun and the asshas she was dreaded by the group and she sad table the constant that the stupic was not the risint and an ort ao an ad destrain and crilling the staby complexion and the side of the satisfaction was interesting the intention was refher to the size which (the sort is the town and the child got the side in a terton cousin from depresing the same starts and make other probably that the stabble conflictation and her own spiritual chair in the shape of a thousaed and she children was not the sake of surprise (or the chick in the same state spraid the sistakree (ost is an edeg that this poor she was an addent to the earth and the poor starts sort of the best the prizzien and the probable and the social she was staled by the sat sat in the same that she was started for a food could greety stands the shadows was the chief the did not the chice was rather to the chief and a strange for the supposed (a sapel for the fact of the stick and the chief (in the same so that the same the same time (which was got the probably the this money for the supposed (and a little should say the very food which was the same the chick was good (the was the sat and dinner with a complexence was started in the same that the side of the same time"
     ]
    }
   ],
   "source": [
    "generate(test_author_model, diversity=0.3, text=\"this is some test text does it really matter what it says \"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0, author_id: 0\n",
      "Epoch 1/10\n",
      "16588/16588 [==============================] - 12s - loss: 4.2805 - main_out_loss: 2.1183 - aux_out_loss: 2.1621    \n",
      "Epoch 2/10\n",
      "16588/16588 [==============================] - 10s - loss: 4.0678 - main_out_loss: 1.9850 - aux_out_loss: 2.0828    \n",
      "Epoch 3/10\n",
      "16588/16588 [==============================] - 10s - loss: 3.9437 - main_out_loss: 1.9022 - aux_out_loss: 2.0414    \n",
      "Epoch 4/10\n",
      "16588/16588 [==============================] - 10s - loss: 3.8604 - main_out_loss: 1.8497 - aux_out_loss: 2.0107    \n",
      "Epoch 5/10\n",
      "16588/16588 [==============================] - 10s - loss: 3.7893 - main_out_loss: 1.8011 - aux_out_loss: 1.9882    \n",
      "Epoch 6/10\n",
      "16588/16588 [==============================] - 10s - loss: 3.7332 - main_out_loss: 1.7678 - aux_out_loss: 1.9654    \n",
      "Epoch 7/10\n",
      "16588/16588 [==============================] - 10s - loss: 3.6906 - main_out_loss: 1.7407 - aux_out_loss: 1.9499    \n",
      "Epoch 8/10\n",
      "16588/16588 [==============================] - 10s - loss: 3.6542 - main_out_loss: 1.7216 - aux_out_loss: 1.9325    \n",
      "Epoch 9/10\n",
      "16588/16588 [==============================] - 10s - loss: 3.6033 - main_out_loss: 1.6869 - aux_out_loss: 1.9164    \n",
      "Epoch 10/10\n",
      "16588/16588 [==============================] - 10s - loss: 3.5817 - main_out_loss: 1.6808 - aux_out_loss: 1.9009    \n",
      "iteration 1, author_id: 1\n",
      "Epoch 1/10\n",
      "16239/16239 [==============================] - 11s - loss: 5.7006 - main_out_loss: 2.9319 - aux_out_loss: 2.7687    \n",
      "Epoch 2/10\n",
      "16239/16239 [==============================] - 10s - loss: 5.2874 - main_out_loss: 2.6824 - aux_out_loss: 2.6050    \n",
      "Epoch 3/10\n",
      "16239/16239 [==============================] - 9s - loss: 5.0462 - main_out_loss: 2.5391 - aux_out_loss: 2.5071     \n",
      "Epoch 4/10\n",
      "16239/16239 [==============================] - 10s - loss: 4.8632 - main_out_loss: 2.4306 - aux_out_loss: 2.4326    \n",
      "Epoch 5/10\n",
      "16239/16239 [==============================] - 10s - loss: 4.7283 - main_out_loss: 2.3474 - aux_out_loss: 2.3809    \n",
      "Epoch 6/10\n",
      "16239/16239 [==============================] - 10s - loss: 4.6126 - main_out_loss: 2.2729 - aux_out_loss: 2.3397    \n",
      "Epoch 7/10\n",
      "16239/16239 [==============================] - 10s - loss: 4.5217 - main_out_loss: 2.2186 - aux_out_loss: 2.3031    \n",
      "Epoch 8/10\n",
      "16239/16239 [==============================] - 10s - loss: 4.4440 - main_out_loss: 2.1663 - aux_out_loss: 2.2777    \n",
      "Epoch 9/10\n",
      "16239/16239 [==============================] - 9s - loss: 4.3766 - main_out_loss: 2.1249 - aux_out_loss: 2.2517     \n",
      "Epoch 10/10\n",
      "16239/16239 [==============================] - 9s - loss: 4.3148 - main_out_loss: 2.0899 - aux_out_loss: 2.2249     \n",
      "iteration 2, author_id: 2\n",
      "Epoch 1/10\n",
      "16362/16362 [==============================] - 12s - loss: 4.2477 - main_out_loss: 2.1239 - aux_out_loss: 2.1238    \n",
      "Epoch 2/10\n",
      "16362/16362 [==============================] - 10s - loss: 4.0805 - main_out_loss: 2.0063 - aux_out_loss: 2.0742    \n",
      "Epoch 3/10\n",
      "16362/16362 [==============================] - 10s - loss: 3.9744 - main_out_loss: 1.9355 - aux_out_loss: 2.0389    \n",
      "Epoch 4/10\n",
      "16362/16362 [==============================] - 10s - loss: 3.8927 - main_out_loss: 1.8766 - aux_out_loss: 2.0160    \n",
      "Epoch 5/10\n",
      "16362/16362 [==============================] - 10s - loss: 3.8354 - main_out_loss: 1.8373 - aux_out_loss: 1.9981    \n",
      "Epoch 6/10\n",
      "16362/16362 [==============================] - 10s - loss: 3.7789 - main_out_loss: 1.7989 - aux_out_loss: 1.9800    \n",
      "Epoch 7/10\n",
      "16362/16362 [==============================] - 10s - loss: 3.7275 - main_out_loss: 1.7636 - aux_out_loss: 1.9639    \n",
      "Epoch 8/10\n",
      "16362/16362 [==============================] - 10s - loss: 3.6926 - main_out_loss: 1.7433 - aux_out_loss: 1.9492    \n",
      "Epoch 9/10\n",
      "16362/16362 [==============================] - 10s - loss: 3.6489 - main_out_loss: 1.7141 - aux_out_loss: 1.9348    \n",
      "Epoch 10/10\n",
      "16362/16362 [==============================] - 10s - loss: 3.6263 - main_out_loss: 1.7018 - aux_out_loss: 1.9244    \n",
      "iteration 3, author_id: 3\n",
      "Epoch 1/10\n",
      "16524/16524 [==============================] - 12s - loss: 4.4449 - main_out_loss: 2.2029 - aux_out_loss: 2.2420    \n",
      "Epoch 2/10\n",
      "16524/16524 [==============================] - 10s - loss: 4.2927 - main_out_loss: 2.0975 - aux_out_loss: 2.1952    \n",
      "Epoch 3/10\n",
      "16524/16524 [==============================] - 10s - loss: 4.1830 - main_out_loss: 2.0226 - aux_out_loss: 2.1603    \n",
      "Epoch 4/10\n",
      "16524/16524 [==============================] - 10s - loss: 4.1065 - main_out_loss: 1.9719 - aux_out_loss: 2.1346    \n",
      "Epoch 5/10\n",
      "16524/16524 [==============================] - 10s - loss: 4.0361 - main_out_loss: 1.9246 - aux_out_loss: 2.1115    \n",
      "Epoch 6/10\n",
      "16524/16524 [==============================] - 10s - loss: 3.9739 - main_out_loss: 1.8838 - aux_out_loss: 2.0901    \n",
      "Epoch 7/10\n",
      "16524/16524 [==============================] - 10s - loss: 3.9339 - main_out_loss: 1.8574 - aux_out_loss: 2.0765    \n",
      "Epoch 8/10\n",
      "16524/16524 [==============================] - 10s - loss: 3.8951 - main_out_loss: 1.8337 - aux_out_loss: 2.0615    \n",
      "Epoch 9/10\n",
      "16524/16524 [==============================] - 10s - loss: 3.8603 - main_out_loss: 1.8092 - aux_out_loss: 2.0511    \n",
      "Epoch 10/10\n",
      "16524/16524 [==============================] - 10s - loss: 3.8285 - main_out_loss: 1.7901 - aux_out_loss: 2.0384    \n",
      "iteration 4, author_id: 4\n",
      "Epoch 1/10\n",
      "16266/16266 [==============================] - 12s - loss: 4.6353 - main_out_loss: 2.3419 - aux_out_loss: 2.2934    \n",
      "Epoch 2/10\n",
      "16266/16266 [==============================] - 10s - loss: 4.4068 - main_out_loss: 2.1922 - aux_out_loss: 2.2146    \n",
      "Epoch 3/10\n",
      "16266/16266 [==============================] - 10s - loss: 4.2790 - main_out_loss: 2.1103 - aux_out_loss: 2.1687    \n",
      "Epoch 4/10\n",
      "16266/16266 [==============================] - 10s - loss: 4.1747 - main_out_loss: 2.0396 - aux_out_loss: 2.1352    \n",
      "Epoch 5/10\n",
      "16266/16266 [==============================] - 10s - loss: 4.0930 - main_out_loss: 1.9872 - aux_out_loss: 2.1059    \n",
      "Epoch 6/10\n",
      "16266/16266 [==============================] - 10s - loss: 4.0266 - main_out_loss: 1.9422 - aux_out_loss: 2.0844    \n",
      "Epoch 7/10\n",
      "16266/16266 [==============================] - 10s - loss: 3.9701 - main_out_loss: 1.9056 - aux_out_loss: 2.0645    \n",
      "Epoch 8/10\n",
      "16266/16266 [==============================] - 10s - loss: 3.9148 - main_out_loss: 1.8741 - aux_out_loss: 2.0407    \n",
      "Epoch 9/10\n",
      "16266/16266 [==============================] - 10s - loss: 3.8636 - main_out_loss: 1.8385 - aux_out_loss: 2.0251    \n",
      "Epoch 10/10\n",
      "16266/16266 [==============================] - 10s - loss: 3.8279 - main_out_loss: 1.8172 - aux_out_loss: 2.0107    \n",
      "iteration 5, author_id: 5\n",
      "Epoch 1/10\n",
      "16449/16449 [==============================] - 12s - loss: 4.2675 - main_out_loss: 2.1164 - aux_out_loss: 2.1511    \n",
      "Epoch 2/10\n",
      "16449/16449 [==============================] - 10s - loss: 4.1007 - main_out_loss: 2.0037 - aux_out_loss: 2.0970    \n",
      "Epoch 3/10\n",
      "16449/16449 [==============================] - 10s - loss: 3.9839 - main_out_loss: 1.9236 - aux_out_loss: 2.0603    \n",
      "Epoch 4/10\n",
      "16449/16449 [==============================] - 10s - loss: 3.9085 - main_out_loss: 1.8738 - aux_out_loss: 2.0348    \n",
      "Epoch 5/10\n",
      "16449/16449 [==============================] - 10s - loss: 3.8440 - main_out_loss: 1.8330 - aux_out_loss: 2.0110    \n",
      "Epoch 6/10\n",
      "16449/16449 [==============================] - 10s - loss: 3.7858 - main_out_loss: 1.7966 - aux_out_loss: 1.9892    \n",
      "Epoch 7/10\n",
      "16449/16449 [==============================] - 10s - loss: 3.7413 - main_out_loss: 1.7687 - aux_out_loss: 1.9725    \n",
      "Epoch 8/10\n",
      "16449/16449 [==============================] - 10s - loss: 3.7011 - main_out_loss: 1.7439 - aux_out_loss: 1.9572    \n",
      "Epoch 9/10\n",
      "16449/16449 [==============================] - 10s - loss: 3.6666 - main_out_loss: 1.7201 - aux_out_loss: 1.9464    \n",
      "Epoch 10/10\n",
      "16449/16449 [==============================] - 10s - loss: 3.6367 - main_out_loss: 1.7012 - aux_out_loss: 1.9355    \n",
      "iteration 6, author_id: 6\n",
      "Epoch 1/10\n",
      "16419/16419 [==============================] - 12s - loss: 4.8882 - main_out_loss: 2.4782 - aux_out_loss: 2.4100    \n",
      "Epoch 2/10\n",
      "16419/16419 [==============================] - 10s - loss: 4.7051 - main_out_loss: 2.3511 - aux_out_loss: 2.3541    \n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16419/16419 [==============================] - 10s - loss: 4.5722 - main_out_loss: 2.2623 - aux_out_loss: 2.3099    \n",
      "Epoch 4/10\n",
      "16419/16419 [==============================] - 10s - loss: 4.4824 - main_out_loss: 2.2037 - aux_out_loss: 2.2787    \n",
      "Epoch 5/10\n",
      "16419/16419 [==============================] - 10s - loss: 4.3920 - main_out_loss: 2.1389 - aux_out_loss: 2.2531    \n",
      "Epoch 6/10\n",
      "16419/16419 [==============================] - 10s - loss: 4.3339 - main_out_loss: 2.0992 - aux_out_loss: 2.2347    \n",
      "Epoch 7/10\n",
      "16419/16419 [==============================] - 10s - loss: 4.2794 - main_out_loss: 2.0642 - aux_out_loss: 2.2152    \n",
      "Epoch 8/10\n",
      "16419/16419 [==============================] - 10s - loss: 4.2283 - main_out_loss: 2.0291 - aux_out_loss: 2.1992    \n",
      "Epoch 9/10\n",
      "16419/16419 [==============================] - 10s - loss: 4.1888 - main_out_loss: 2.0047 - aux_out_loss: 2.1841    \n",
      "Epoch 10/10\n",
      "16419/16419 [==============================] - 10s - loss: 4.1531 - main_out_loss: 1.9848 - aux_out_loss: 2.1682    \n",
      "iteration 7, author_id: 7\n",
      "Epoch 1/10\n",
      "16385/16385 [==============================] - 12s - loss: 5.0315 - main_out_loss: 2.5657 - aux_out_loss: 2.4658    \n",
      "Epoch 2/10\n",
      "16385/16385 [==============================] - 10s - loss: 4.7432 - main_out_loss: 2.3761 - aux_out_loss: 2.3671    \n",
      "Epoch 3/10\n",
      "16385/16385 [==============================] - 10s - loss: 4.5961 - main_out_loss: 2.2833 - aux_out_loss: 2.3128    \n",
      "Epoch 4/10\n",
      "16385/16385 [==============================] - 10s - loss: 4.4766 - main_out_loss: 2.1996 - aux_out_loss: 2.2770    \n",
      "Epoch 5/10\n",
      "16385/16385 [==============================] - 10s - loss: 4.3761 - main_out_loss: 2.1344 - aux_out_loss: 2.2416    \n",
      "Epoch 6/10\n",
      "16385/16385 [==============================] - 10s - loss: 4.3217 - main_out_loss: 2.0977 - aux_out_loss: 2.2240    \n",
      "Epoch 7/10\n",
      "16385/16385 [==============================] - 10s - loss: 4.2467 - main_out_loss: 2.0460 - aux_out_loss: 2.2007    \n",
      "Epoch 8/10\n",
      "16385/16385 [==============================] - 10s - loss: 4.1988 - main_out_loss: 2.0157 - aux_out_loss: 2.1831    \n",
      "Epoch 9/10\n",
      "16385/16385 [==============================] - 10s - loss: 4.1487 - main_out_loss: 1.9822 - aux_out_loss: 2.1665    \n",
      "Epoch 10/10\n",
      "16385/16385 [==============================] - 10s - loss: 4.1169 - main_out_loss: 1.9640 - aux_out_loss: 2.1529    \n",
      "iteration 8, author_id: 8\n",
      "Epoch 1/10\n",
      "16541/16541 [==============================] - 12s - loss: 4.0294 - main_out_loss: 1.9914 - aux_out_loss: 2.0380    \n",
      "Epoch 2/10\n",
      "16541/16541 [==============================] - 10s - loss: 3.8739 - main_out_loss: 1.8862 - aux_out_loss: 1.9877    \n",
      "Epoch 3/10\n",
      "16541/16541 [==============================] - 10s - loss: 3.7720 - main_out_loss: 1.8156 - aux_out_loss: 1.9564    \n",
      "Epoch 4/10\n",
      "16541/16541 [==============================] - 10s - loss: 3.7048 - main_out_loss: 1.7760 - aux_out_loss: 1.9288    \n",
      "Epoch 5/10\n",
      "16541/16541 [==============================] - 10s - loss: 3.6297 - main_out_loss: 1.7227 - aux_out_loss: 1.9070    \n",
      "Epoch 6/10\n",
      "16541/16541 [==============================] - 10s - loss: 3.5862 - main_out_loss: 1.6945 - aux_out_loss: 1.8917    \n",
      "Epoch 7/10\n",
      "16541/16541 [==============================] - 10s - loss: 3.5418 - main_out_loss: 1.6674 - aux_out_loss: 1.8744    \n",
      "Epoch 8/10\n",
      "16541/16541 [==============================] - 10s - loss: 3.5011 - main_out_loss: 1.6402 - aux_out_loss: 1.8609    \n",
      "Epoch 9/10\n",
      "16541/16541 [==============================] - 10s - loss: 3.4748 - main_out_loss: 1.6268 - aux_out_loss: 1.8480    \n",
      "Epoch 10/10\n",
      "16541/16541 [==============================] - 10s - loss: 3.4442 - main_out_loss: 1.6071 - aux_out_loss: 1.8371    \n",
      "iteration 9, author_id: 9\n",
      "Epoch 1/10\n",
      "16523/16523 [==============================] - 12s - loss: 4.3628 - main_out_loss: 2.1988 - aux_out_loss: 2.1640    \n",
      "Epoch 2/10\n",
      "16523/16523 [==============================] - 10s - loss: 4.2044 - main_out_loss: 2.0874 - aux_out_loss: 2.1170    \n",
      "Epoch 3/10\n",
      "16523/16523 [==============================] - 10s - loss: 4.0871 - main_out_loss: 2.0066 - aux_out_loss: 2.0805    \n",
      "Epoch 4/10\n",
      "16523/16523 [==============================] - 10s - loss: 3.9994 - main_out_loss: 1.9431 - aux_out_loss: 2.0563    \n",
      "Epoch 5/10\n",
      "16523/16523 [==============================] - 10s - loss: 3.9337 - main_out_loss: 1.8973 - aux_out_loss: 2.0364    \n",
      "Epoch 6/10\n",
      "16523/16523 [==============================] - 10s - loss: 3.8796 - main_out_loss: 1.8627 - aux_out_loss: 2.0169    \n",
      "Epoch 7/10\n",
      "16523/16523 [==============================] - 10s - loss: 3.8291 - main_out_loss: 1.8294 - aux_out_loss: 1.9997    \n",
      "Epoch 8/10\n",
      "16523/16523 [==============================] - 10s - loss: 3.7948 - main_out_loss: 1.8083 - aux_out_loss: 1.9865    \n",
      "Epoch 9/10\n",
      "16523/16523 [==============================] - 10s - loss: 3.7558 - main_out_loss: 1.7855 - aux_out_loss: 1.9703    \n",
      "Epoch 10/10\n",
      "16523/16523 [==============================] - 10s - loss: 3.7272 - main_out_loss: 1.7658 - aux_out_loss: 1.9614    \n",
      "iteration 10, author_id: 10\n",
      "Epoch 1/10\n",
      "16357/16357 [==============================] - 13s - loss: 5.6163 - main_out_loss: 2.9181 - aux_out_loss: 2.6982    \n",
      "Epoch 2/10\n",
      "16357/16357 [==============================] - 10s - loss: 5.2125 - main_out_loss: 2.6504 - aux_out_loss: 2.5621    \n",
      "Epoch 3/10\n",
      "16357/16357 [==============================] - 10s - loss: 5.0027 - main_out_loss: 2.5101 - aux_out_loss: 2.4926    \n",
      "Epoch 4/10\n",
      "16357/16357 [==============================] - 10s - loss: 4.8495 - main_out_loss: 2.4084 - aux_out_loss: 2.4411    \n",
      "Epoch 5/10\n",
      "16357/16357 [==============================] - 10s - loss: 4.7489 - main_out_loss: 2.3426 - aux_out_loss: 2.4063    \n",
      "Epoch 6/10\n",
      "16357/16357 [==============================] - 10s - loss: 4.6432 - main_out_loss: 2.2754 - aux_out_loss: 2.3678    \n",
      "Epoch 7/10\n",
      "16357/16357 [==============================] - 10s - loss: 4.5753 - main_out_loss: 2.2310 - aux_out_loss: 2.3443    \n",
      "Epoch 8/10\n",
      "16357/16357 [==============================] - 10s - loss: 4.4966 - main_out_loss: 2.1812 - aux_out_loss: 2.3154    \n",
      "Epoch 9/10\n",
      "16357/16357 [==============================] - 10s - loss: 4.4383 - main_out_loss: 2.1429 - aux_out_loss: 2.2955    \n",
      "Epoch 10/10\n",
      "16357/16357 [==============================] - 10s - loss: 4.3921 - main_out_loss: 2.1168 - aux_out_loss: 2.2753    \n",
      "iteration 11, author_id: 11\n",
      "Epoch 1/10\n",
      "16533/16533 [==============================] - 13s - loss: 4.7251 - main_out_loss: 2.3897 - aux_out_loss: 2.3353    \n",
      "Epoch 2/10\n",
      "16533/16533 [==============================] - 10s - loss: 4.5295 - main_out_loss: 2.2555 - aux_out_loss: 2.2740    \n",
      "Epoch 3/10\n",
      "16533/16533 [==============================] - 10s - loss: 4.3945 - main_out_loss: 2.1595 - aux_out_loss: 2.2350    \n",
      "Epoch 4/10\n",
      "16533/16533 [==============================] - 10s - loss: 4.3017 - main_out_loss: 2.0974 - aux_out_loss: 2.2043    \n",
      "Epoch 5/10\n",
      "16533/16533 [==============================] - 10s - loss: 4.2325 - main_out_loss: 2.0508 - aux_out_loss: 2.1817    \n",
      "Epoch 6/10\n",
      "16533/16533 [==============================] - 10s - loss: 4.1663 - main_out_loss: 2.0051 - aux_out_loss: 2.1612    \n",
      "Epoch 7/10\n",
      "16533/16533 [==============================] - 10s - loss: 4.1116 - main_out_loss: 1.9711 - aux_out_loss: 2.1405    \n",
      "Epoch 8/10\n",
      "16533/16533 [==============================] - 10s - loss: 4.0746 - main_out_loss: 1.9468 - aux_out_loss: 2.1277    \n",
      "Epoch 9/10\n",
      "16533/16533 [==============================] - 10s - loss: 4.0297 - main_out_loss: 1.9188 - aux_out_loss: 2.1108    \n",
      "Epoch 10/10\n",
      "16533/16533 [==============================] - 10s - loss: 3.9926 - main_out_loss: 1.8960 - aux_out_loss: 2.0967    \n",
      "iteration 12, author_id: 12\n",
      "Epoch 1/10\n",
      "16304/16304 [==============================] - 13s - loss: 4.6451 - main_out_loss: 2.3305 - aux_out_loss: 2.3145    \n",
      "Epoch 2/10\n",
      "16304/16304 [==============================] - 10s - loss: 4.4491 - main_out_loss: 2.1977 - aux_out_loss: 2.2514    \n",
      "Epoch 3/10\n",
      "16304/16304 [==============================] - 10s - loss: 4.3262 - main_out_loss: 2.1145 - aux_out_loss: 2.2117    \n",
      "Epoch 4/10\n",
      "16304/16304 [==============================] - 10s - loss: 4.2340 - main_out_loss: 2.0511 - aux_out_loss: 2.1829    \n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16304/16304 [==============================] - 10s - loss: 4.1480 - main_out_loss: 1.9942 - aux_out_loss: 2.1539    \n",
      "Epoch 6/10\n",
      "16304/16304 [==============================] - 10s - loss: 4.0924 - main_out_loss: 1.9573 - aux_out_loss: 2.1350    \n",
      "Epoch 7/10\n",
      "16304/16304 [==============================] - 10s - loss: 4.0463 - main_out_loss: 1.9303 - aux_out_loss: 2.1160    \n",
      "Epoch 8/10\n",
      "16304/16304 [==============================] - 10s - loss: 3.9906 - main_out_loss: 1.8931 - aux_out_loss: 2.0975    \n",
      "Epoch 9/10\n",
      "16304/16304 [==============================] - 10s - loss: 3.9525 - main_out_loss: 1.8705 - aux_out_loss: 2.0820    \n",
      "Epoch 10/10\n",
      "16304/16304 [==============================] - 10s - loss: 3.9160 - main_out_loss: 1.8459 - aux_out_loss: 2.0701    \n",
      "iteration 13, author_id: 13\n",
      "Epoch 1/10\n",
      "16523/16523 [==============================] - 13s - loss: 4.0897 - main_out_loss: 2.0214 - aux_out_loss: 2.0682    \n",
      "Epoch 2/10\n",
      "16523/16523 [==============================] - 10s - loss: 3.9643 - main_out_loss: 1.9401 - aux_out_loss: 2.0242    \n",
      "Epoch 3/10\n",
      "16523/16523 [==============================] - 10s - loss: 3.8753 - main_out_loss: 1.8748 - aux_out_loss: 2.0005    \n",
      "Epoch 4/10\n",
      "16523/16523 [==============================] - 10s - loss: 3.7969 - main_out_loss: 1.8193 - aux_out_loss: 1.9776    \n",
      "Epoch 5/10\n",
      "16523/16523 [==============================] - 10s - loss: 3.7515 - main_out_loss: 1.7920 - aux_out_loss: 1.9594    \n",
      "Epoch 6/10\n",
      "16523/16523 [==============================] - 10s - loss: 3.6980 - main_out_loss: 1.7548 - aux_out_loss: 1.9432    \n",
      "Epoch 7/10\n",
      "16523/16523 [==============================] - 10s - loss: 3.6592 - main_out_loss: 1.7305 - aux_out_loss: 1.9288    \n",
      "Epoch 8/10\n",
      "16523/16523 [==============================] - 10s - loss: 3.6212 - main_out_loss: 1.7047 - aux_out_loss: 1.9164    \n",
      "Epoch 9/10\n",
      "16523/16523 [==============================] - 10s - loss: 3.5969 - main_out_loss: 1.6915 - aux_out_loss: 1.9054    \n",
      "Epoch 10/10\n",
      "16523/16523 [==============================] - 10s - loss: 3.5677 - main_out_loss: 1.6702 - aux_out_loss: 1.8975    \n",
      "iteration 14, author_id: 14\n",
      "Epoch 1/10\n",
      "16132/16132 [==============================] - 13s - loss: 5.4480 - main_out_loss: 2.7897 - aux_out_loss: 2.6583    \n",
      "Epoch 2/10\n",
      "16132/16132 [==============================] - 9s - loss: 5.1834 - main_out_loss: 2.6146 - aux_out_loss: 2.5688     \n",
      "Epoch 3/10\n",
      "16132/16132 [==============================] - 9s - loss: 5.0051 - main_out_loss: 2.4934 - aux_out_loss: 2.5117     \n",
      "Epoch 4/10\n",
      "16132/16132 [==============================] - 9s - loss: 4.8878 - main_out_loss: 2.4202 - aux_out_loss: 2.4676     \n",
      "Epoch 5/10\n",
      "16132/16132 [==============================] - 9s - loss: 4.7945 - main_out_loss: 2.3602 - aux_out_loss: 2.4343     \n",
      "Epoch 6/10\n",
      "16132/16132 [==============================] - 9s - loss: 4.7183 - main_out_loss: 2.3064 - aux_out_loss: 2.4120     \n",
      "Epoch 7/10\n",
      "16132/16132 [==============================] - 9s - loss: 4.6445 - main_out_loss: 2.2595 - aux_out_loss: 2.3850     \n",
      "Epoch 8/10\n",
      "16132/16132 [==============================] - 9s - loss: 4.6077 - main_out_loss: 2.2370 - aux_out_loss: 2.3707     \n",
      "Epoch 9/10\n",
      "16132/16132 [==============================] - 9s - loss: 4.5484 - main_out_loss: 2.1937 - aux_out_loss: 2.3548     \n",
      "Epoch 10/10\n",
      "16132/16132 [==============================] - 9s - loss: 4.5089 - main_out_loss: 2.1756 - aux_out_loss: 2.3333     \n",
      "iteration 15, author_id: 15\n",
      "Epoch 1/10\n",
      "16555/16555 [==============================] - 13s - loss: 4.1841 - main_out_loss: 2.0644 - aux_out_loss: 2.1198    \n",
      "Epoch 2/10\n",
      "16555/16555 [==============================] - 10s - loss: 4.0384 - main_out_loss: 1.9647 - aux_out_loss: 2.0737    \n",
      "Epoch 3/10\n",
      "16555/16555 [==============================] - 10s - loss: 3.9374 - main_out_loss: 1.8942 - aux_out_loss: 2.0431    \n",
      "Epoch 4/10\n",
      "16555/16555 [==============================] - 10s - loss: 3.8640 - main_out_loss: 1.8451 - aux_out_loss: 2.0189    \n",
      "Epoch 5/10\n",
      "16555/16555 [==============================] - 10s - loss: 3.8055 - main_out_loss: 1.8083 - aux_out_loss: 1.9973    \n",
      "Epoch 6/10\n",
      "16555/16555 [==============================] - 10s - loss: 3.7515 - main_out_loss: 1.7708 - aux_out_loss: 1.9807    \n",
      "Epoch 7/10\n",
      "16555/16555 [==============================] - 10s - loss: 3.7072 - main_out_loss: 1.7434 - aux_out_loss: 1.9638    \n",
      "Epoch 8/10\n",
      "16555/16555 [==============================] - 10s - loss: 3.6761 - main_out_loss: 1.7259 - aux_out_loss: 1.9502    \n",
      "Epoch 9/10\n",
      "16555/16555 [==============================] - 10s - loss: 3.6492 - main_out_loss: 1.7111 - aux_out_loss: 1.9380    \n",
      "Epoch 10/10\n",
      "16555/16555 [==============================] - 10s - loss: 3.6171 - main_out_loss: 1.6894 - aux_out_loss: 1.9277    \n",
      "iteration 16, author_id: 16\n",
      "Epoch 1/10\n",
      "16381/16381 [==============================] - 13s - loss: 4.2027 - main_out_loss: 2.0886 - aux_out_loss: 2.1142    \n",
      "Epoch 2/10\n",
      "16381/16381 [==============================] - 10s - loss: 4.0238 - main_out_loss: 1.9640 - aux_out_loss: 2.0597    \n",
      "Epoch 3/10\n",
      "16381/16381 [==============================] - 10s - loss: 3.9224 - main_out_loss: 1.8945 - aux_out_loss: 2.0278    \n",
      "Epoch 4/10\n",
      "16381/16381 [==============================] - 10s - loss: 3.8479 - main_out_loss: 1.8472 - aux_out_loss: 2.0006    \n",
      "Epoch 5/10\n",
      "16381/16381 [==============================] - 10s - loss: 3.7796 - main_out_loss: 1.8018 - aux_out_loss: 1.9777    \n",
      "Epoch 6/10\n",
      "16381/16381 [==============================] - 10s - loss: 3.7273 - main_out_loss: 1.7700 - aux_out_loss: 1.9574    \n",
      "Epoch 7/10\n",
      "16381/16381 [==============================] - 10s - loss: 3.6869 - main_out_loss: 1.7433 - aux_out_loss: 1.9435    \n",
      "Epoch 8/10\n",
      "16381/16381 [==============================] - 10s - loss: 3.6367 - main_out_loss: 1.7094 - aux_out_loss: 1.9273    \n",
      "Epoch 9/10\n",
      "16381/16381 [==============================] - 10s - loss: 3.5956 - main_out_loss: 1.6827 - aux_out_loss: 1.9129    \n",
      "Epoch 10/10\n",
      "16381/16381 [==============================] - 10s - loss: 3.5686 - main_out_loss: 1.6698 - aux_out_loss: 1.8988    \n",
      "iteration 17, author_id: 17\n",
      "Epoch 1/10\n",
      "16490/16490 [==============================] - 13s - loss: 4.0829 - main_out_loss: 2.0008 - aux_out_loss: 2.0821    \n",
      "Epoch 2/10\n",
      "16490/16490 [==============================] - 10s - loss: 3.9264 - main_out_loss: 1.8934 - aux_out_loss: 2.0330    \n",
      "Epoch 3/10\n",
      "16490/16490 [==============================] - 10s - loss: 3.8430 - main_out_loss: 1.8406 - aux_out_loss: 2.0024    \n",
      "Epoch 4/10\n",
      "16490/16490 [==============================] - 10s - loss: 3.7563 - main_out_loss: 1.7823 - aux_out_loss: 1.9740    \n",
      "Epoch 5/10\n",
      "16490/16490 [==============================] - 10s - loss: 3.7037 - main_out_loss: 1.7469 - aux_out_loss: 1.9568    \n",
      "Epoch 6/10\n",
      "16490/16490 [==============================] - 10s - loss: 3.6463 - main_out_loss: 1.7093 - aux_out_loss: 1.9369    \n",
      "Epoch 7/10\n",
      "16490/16490 [==============================] - 10s - loss: 3.6097 - main_out_loss: 1.6865 - aux_out_loss: 1.9232    \n",
      "Epoch 8/10\n",
      "16490/16490 [==============================] - 10s - loss: 3.5708 - main_out_loss: 1.6640 - aux_out_loss: 1.9068    \n",
      "Epoch 9/10\n",
      "16490/16490 [==============================] - 10s - loss: 3.5301 - main_out_loss: 1.6384 - aux_out_loss: 1.8918    \n",
      "Epoch 10/10\n",
      "16490/16490 [==============================] - 10s - loss: 3.5193 - main_out_loss: 1.6333 - aux_out_loss: 1.8861    \n",
      "iteration 18, author_id: 18\n",
      "Epoch 1/10\n",
      "16533/16533 [==============================] - 13s - loss: 4.4099 - main_out_loss: 2.2026 - aux_out_loss: 2.2074    \n",
      "Epoch 2/10\n",
      "16533/16533 [==============================] - 10s - loss: 4.2480 - main_out_loss: 2.0877 - aux_out_loss: 2.1603    \n",
      "Epoch 3/10\n",
      "16533/16533 [==============================] - 10s - loss: 4.1475 - main_out_loss: 2.0223 - aux_out_loss: 2.1253    \n",
      "Epoch 4/10\n",
      "16533/16533 [==============================] - 10s - loss: 4.0555 - main_out_loss: 1.9563 - aux_out_loss: 2.0992    \n",
      "Epoch 5/10\n",
      "16533/16533 [==============================] - 10s - loss: 3.9915 - main_out_loss: 1.9113 - aux_out_loss: 2.0802    \n",
      "Epoch 6/10\n",
      "16533/16533 [==============================] - 10s - loss: 3.9291 - main_out_loss: 1.8710 - aux_out_loss: 2.0581    \n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16533/16533 [==============================] - 10s - loss: 3.8853 - main_out_loss: 1.8419 - aux_out_loss: 2.0434    \n",
      "Epoch 8/10\n",
      "16533/16533 [==============================] - 10s - loss: 3.8489 - main_out_loss: 1.8191 - aux_out_loss: 2.0298    \n",
      "Epoch 9/10\n",
      "16533/16533 [==============================] - 10s - loss: 3.8148 - main_out_loss: 1.7984 - aux_out_loss: 2.0164    \n",
      "Epoch 10/10\n",
      "16533/16533 [==============================] - 10s - loss: 3.7799 - main_out_loss: 1.7782 - aux_out_loss: 2.0017    \n",
      "iteration 19, author_id: 19\n",
      "Epoch 1/10\n",
      "16432/16432 [==============================] - 13s - loss: 4.4749 - main_out_loss: 2.2355 - aux_out_loss: 2.2395    \n",
      "Epoch 2/10\n",
      "16432/16432 [==============================] - 10s - loss: 4.2154 - main_out_loss: 2.0694 - aux_out_loss: 2.1460    \n",
      "Epoch 3/10\n",
      "16432/16432 [==============================] - 10s - loss: 4.0629 - main_out_loss: 1.9734 - aux_out_loss: 2.0895    \n",
      "Epoch 4/10\n",
      "16432/16432 [==============================] - 10s - loss: 3.9493 - main_out_loss: 1.9007 - aux_out_loss: 2.0486    \n",
      "Epoch 5/10\n",
      "16432/16432 [==============================] - 10s - loss: 3.8607 - main_out_loss: 1.8408 - aux_out_loss: 2.0200    \n",
      "Epoch 6/10\n",
      "16432/16432 [==============================] - 10s - loss: 3.7965 - main_out_loss: 1.8033 - aux_out_loss: 1.9932    \n",
      "Epoch 7/10\n",
      "16432/16432 [==============================] - 10s - loss: 3.7425 - main_out_loss: 1.7721 - aux_out_loss: 1.9704    \n",
      "Epoch 8/10\n",
      "16432/16432 [==============================] - 10s - loss: 3.6865 - main_out_loss: 1.7367 - aux_out_loss: 1.9498    \n",
      "Epoch 9/10\n",
      "16432/16432 [==============================] - 10s - loss: 3.6516 - main_out_loss: 1.7175 - aux_out_loss: 1.9341    \n",
      "Epoch 10/10\n",
      "16432/16432 [==============================] - 10s - loss: 3.6104 - main_out_loss: 1.6924 - aux_out_loss: 1.9179    \n",
      "iteration 20, author_id: 20\n",
      "Epoch 1/10\n",
      "16526/16526 [==============================] - 13s - loss: 4.6521 - main_out_loss: 2.3206 - aux_out_loss: 2.3314    \n",
      "Epoch 2/10\n",
      "16526/16526 [==============================] - 10s - loss: 4.4573 - main_out_loss: 2.1905 - aux_out_loss: 2.2668    \n",
      "Epoch 3/10\n",
      "16526/16526 [==============================] - 10s - loss: 4.3244 - main_out_loss: 2.0983 - aux_out_loss: 2.2261    \n",
      "Epoch 4/10\n",
      "16526/16526 [==============================] - 10s - loss: 4.2227 - main_out_loss: 2.0329 - aux_out_loss: 2.1898    \n",
      "Epoch 5/10\n",
      "16526/16526 [==============================] - 10s - loss: 4.1618 - main_out_loss: 1.9912 - aux_out_loss: 2.1706    \n",
      "Epoch 6/10\n",
      "16526/16526 [==============================] - 10s - loss: 4.0958 - main_out_loss: 1.9479 - aux_out_loss: 2.1479    \n",
      "Epoch 7/10\n",
      "16526/16526 [==============================] - 10s - loss: 4.0466 - main_out_loss: 1.9182 - aux_out_loss: 2.1283    \n",
      "Epoch 8/10\n",
      "16526/16526 [==============================] - 10s - loss: 3.9937 - main_out_loss: 1.8843 - aux_out_loss: 2.1094    \n",
      "Epoch 9/10\n",
      "16526/16526 [==============================] - 10s - loss: 3.9581 - main_out_loss: 1.8658 - aux_out_loss: 2.0923    \n",
      "Epoch 10/10\n",
      "16526/16526 [==============================] - 10s - loss: 3.9241 - main_out_loss: 1.8458 - aux_out_loss: 2.0783    \n",
      "iteration 21, author_id: 21\n",
      "Epoch 1/10\n",
      "16468/16468 [==============================] - 14s - loss: 4.4182 - main_out_loss: 2.2137 - aux_out_loss: 2.2045    \n",
      "Epoch 2/10\n",
      "16468/16468 [==============================] - 10s - loss: 4.2508 - main_out_loss: 2.0959 - aux_out_loss: 2.1549    \n",
      "Epoch 3/10\n",
      "16468/16468 [==============================] - 10s - loss: 4.1368 - main_out_loss: 2.0183 - aux_out_loss: 2.1184    \n",
      "Epoch 4/10\n",
      "16468/16468 [==============================] - 10s - loss: 4.0444 - main_out_loss: 1.9553 - aux_out_loss: 2.0892    \n",
      "Epoch 5/10\n",
      "16468/16468 [==============================] - 10s - loss: 3.9851 - main_out_loss: 1.9129 - aux_out_loss: 2.0722    \n",
      "Epoch 6/10\n",
      "16468/16468 [==============================] - 10s - loss: 3.9291 - main_out_loss: 1.8792 - aux_out_loss: 2.0499    \n",
      "Epoch 7/10\n",
      "16468/16468 [==============================] - 10s - loss: 3.8836 - main_out_loss: 1.8465 - aux_out_loss: 2.0371    \n",
      "Epoch 8/10\n",
      "16468/16468 [==============================] - 10s - loss: 3.8377 - main_out_loss: 1.8188 - aux_out_loss: 2.0189    \n",
      "Epoch 9/10\n",
      "16468/16468 [==============================] - 10s - loss: 3.8057 - main_out_loss: 1.7978 - aux_out_loss: 2.0078    \n",
      "Epoch 10/10\n",
      "16468/16468 [==============================] - 10s - loss: 3.7743 - main_out_loss: 1.7799 - aux_out_loss: 1.9944    \n",
      "iteration 22, author_id: 22\n",
      "Epoch 1/10\n",
      "16593/16593 [==============================] - 14s - loss: 4.2775 - main_out_loss: 2.1253 - aux_out_loss: 2.1522    \n",
      "Epoch 2/10\n",
      "16593/16593 [==============================] - 10s - loss: 4.1226 - main_out_loss: 2.0143 - aux_out_loss: 2.1083    \n",
      "Epoch 3/10\n",
      "16593/16593 [==============================] - 10s - loss: 4.0291 - main_out_loss: 1.9549 - aux_out_loss: 2.0742    \n",
      "Epoch 4/10\n",
      "16593/16593 [==============================] - 10s - loss: 3.9469 - main_out_loss: 1.8950 - aux_out_loss: 2.0519    \n",
      "Epoch 5/10\n",
      "16593/16593 [==============================] - 10s - loss: 3.8911 - main_out_loss: 1.8593 - aux_out_loss: 2.0318    \n",
      "Epoch 6/10\n",
      "16593/16593 [==============================] - 10s - loss: 3.8287 - main_out_loss: 1.8168 - aux_out_loss: 2.0120    \n",
      "Epoch 7/10\n",
      "16593/16593 [==============================] - 10s - loss: 3.7895 - main_out_loss: 1.7906 - aux_out_loss: 1.9989    \n",
      "Epoch 8/10\n",
      "16593/16593 [==============================] - 10s - loss: 3.7547 - main_out_loss: 1.7700 - aux_out_loss: 1.9847    \n",
      "Epoch 9/10\n",
      "16593/16593 [==============================] - 10s - loss: 3.7204 - main_out_loss: 1.7482 - aux_out_loss: 1.9722    \n",
      "Epoch 10/10\n",
      "16593/16593 [==============================] - 10s - loss: 3.6927 - main_out_loss: 1.7289 - aux_out_loss: 1.9639    \n",
      "iteration 23, author_id: 23\n",
      "Epoch 1/10\n",
      "16543/16543 [==============================] - 14s - loss: 4.2756 - main_out_loss: 2.1179 - aux_out_loss: 2.1577    \n",
      "Epoch 2/10\n",
      "16543/16543 [==============================] - 10s - loss: 4.1331 - main_out_loss: 2.0154 - aux_out_loss: 2.1177    \n",
      "Epoch 3/10\n",
      "16543/16543 [==============================] - 10s - loss: 4.0502 - main_out_loss: 1.9573 - aux_out_loss: 2.0928    \n",
      "Epoch 4/10\n",
      "16543/16543 [==============================] - 10s - loss: 3.9728 - main_out_loss: 1.9059 - aux_out_loss: 2.0669    \n",
      "Epoch 5/10\n",
      "16543/16543 [==============================] - 10s - loss: 3.9108 - main_out_loss: 1.8641 - aux_out_loss: 2.0467    \n",
      "Epoch 6/10\n",
      "16543/16543 [==============================] - 10s - loss: 3.8699 - main_out_loss: 1.8361 - aux_out_loss: 2.0338    \n",
      "Epoch 7/10\n",
      "16543/16543 [==============================] - 10s - loss: 3.8344 - main_out_loss: 1.8142 - aux_out_loss: 2.0202    \n",
      "Epoch 8/10\n",
      "16543/16543 [==============================] - 10s - loss: 3.7845 - main_out_loss: 1.7799 - aux_out_loss: 2.0046    \n",
      "Epoch 9/10\n",
      "16543/16543 [==============================] - 10s - loss: 3.7565 - main_out_loss: 1.7618 - aux_out_loss: 1.9947    \n",
      "Epoch 10/10\n",
      "16543/16543 [==============================] - 10s - loss: 3.7314 - main_out_loss: 1.7488 - aux_out_loss: 1.9825    \n",
      "iteration 24, author_id: 24\n",
      "Epoch 1/10\n",
      "16514/16514 [==============================] - 14s - loss: 4.4655 - main_out_loss: 2.2083 - aux_out_loss: 2.2572    \n",
      "Epoch 2/10\n",
      "16514/16514 [==============================] - 10s - loss: 4.2981 - main_out_loss: 2.0997 - aux_out_loss: 2.1984    \n",
      "Epoch 3/10\n",
      "16514/16514 [==============================] - 10s - loss: 4.1788 - main_out_loss: 2.0199 - aux_out_loss: 2.1588    \n",
      "Epoch 4/10\n",
      "16514/16514 [==============================] - 10s - loss: 4.0960 - main_out_loss: 1.9681 - aux_out_loss: 2.1279    \n",
      "Epoch 5/10\n",
      "16514/16514 [==============================] - 10s - loss: 4.0386 - main_out_loss: 1.9292 - aux_out_loss: 2.1095    \n",
      "Epoch 6/10\n",
      "16514/16514 [==============================] - 10s - loss: 3.9880 - main_out_loss: 1.8991 - aux_out_loss: 2.0889    \n",
      "Epoch 7/10\n",
      "16514/16514 [==============================] - 10s - loss: 3.9376 - main_out_loss: 1.8651 - aux_out_loss: 2.0725    \n",
      "Epoch 8/10\n",
      "16514/16514 [==============================] - 10s - loss: 3.8887 - main_out_loss: 1.8331 - aux_out_loss: 2.0557    \n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16514/16514 [==============================] - 10s - loss: 3.8644 - main_out_loss: 1.8212 - aux_out_loss: 2.0432    \n",
      "Epoch 10/10\n",
      "16514/16514 [==============================] - 10s - loss: 3.8271 - main_out_loss: 1.7968 - aux_out_loss: 2.0304    \n",
      "iteration 25, author_id: 25\n",
      "Epoch 1/10\n",
      "16379/16379 [==============================] - 14s - loss: 4.3433 - main_out_loss: 2.1602 - aux_out_loss: 2.1831    \n",
      "Epoch 2/10\n",
      "16379/16379 [==============================] - 10s - loss: 4.1899 - main_out_loss: 2.0576 - aux_out_loss: 2.1323    \n",
      "Epoch 3/10\n",
      "16379/16379 [==============================] - 10s - loss: 4.0781 - main_out_loss: 1.9753 - aux_out_loss: 2.1028    \n",
      "Epoch 4/10\n",
      "16379/16379 [==============================] - 10s - loss: 4.0012 - main_out_loss: 1.9236 - aux_out_loss: 2.0777    \n",
      "Epoch 5/10\n",
      "16379/16379 [==============================] - 10s - loss: 3.9286 - main_out_loss: 1.8770 - aux_out_loss: 2.0516    \n",
      "Epoch 6/10\n",
      "16379/16379 [==============================] - 10s - loss: 3.8910 - main_out_loss: 1.8486 - aux_out_loss: 2.0423    \n",
      "Epoch 7/10\n",
      "16379/16379 [==============================] - 10s - loss: 3.8306 - main_out_loss: 1.8082 - aux_out_loss: 2.0224    \n",
      "Epoch 8/10\n",
      "16379/16379 [==============================] - 10s - loss: 3.8022 - main_out_loss: 1.7922 - aux_out_loss: 2.0100    \n",
      "Epoch 9/10\n",
      "16379/16379 [==============================] - 10s - loss: 3.7645 - main_out_loss: 1.7693 - aux_out_loss: 1.9951    \n",
      "Epoch 10/10\n",
      "16379/16379 [==============================] - 10s - loss: 3.7287 - main_out_loss: 1.7450 - aux_out_loss: 1.9837    \n",
      "iteration 26, author_id: 26\n",
      "Epoch 1/10\n",
      "16422/16422 [==============================] - 14s - loss: 4.4097 - main_out_loss: 2.1911 - aux_out_loss: 2.2186    \n",
      "Epoch 2/10\n",
      "16422/16422 [==============================] - 10s - loss: 4.2331 - main_out_loss: 2.0710 - aux_out_loss: 2.1621    \n",
      "Epoch 3/10\n",
      "16422/16422 [==============================] - 10s - loss: 4.1134 - main_out_loss: 1.9911 - aux_out_loss: 2.1223    \n",
      "Epoch 4/10\n",
      "16422/16422 [==============================] - 10s - loss: 4.0308 - main_out_loss: 1.9354 - aux_out_loss: 2.0954    \n",
      "Epoch 5/10\n",
      "16422/16422 [==============================] - 10s - loss: 3.9616 - main_out_loss: 1.8939 - aux_out_loss: 2.0677    \n",
      "Epoch 6/10\n",
      "16422/16422 [==============================] - 10s - loss: 3.9115 - main_out_loss: 1.8573 - aux_out_loss: 2.0542    \n",
      "Epoch 7/10\n",
      "16422/16422 [==============================] - 10s - loss: 3.8619 - main_out_loss: 1.8261 - aux_out_loss: 2.0359    \n",
      "Epoch 8/10\n",
      "16422/16422 [==============================] - 10s - loss: 3.8226 - main_out_loss: 1.8035 - aux_out_loss: 2.0191    \n",
      "Epoch 9/10\n",
      "16422/16422 [==============================] - 10s - loss: 3.7827 - main_out_loss: 1.7781 - aux_out_loss: 2.0046    \n",
      "Epoch 10/10\n",
      "16422/16422 [==============================] - 10s - loss: 3.7520 - main_out_loss: 1.7597 - aux_out_loss: 1.9923    \n",
      "iteration 27, author_id: 27\n",
      "Epoch 1/10\n",
      "16357/16357 [==============================] - 14s - loss: 4.1617 - main_out_loss: 2.0611 - aux_out_loss: 2.1006    \n",
      "Epoch 2/10\n",
      "16357/16357 [==============================] - 10s - loss: 4.0205 - main_out_loss: 1.9629 - aux_out_loss: 2.0576    \n",
      "Epoch 3/10\n",
      "16357/16357 [==============================] - 10s - loss: 3.9270 - main_out_loss: 1.9018 - aux_out_loss: 2.0252    \n",
      "Epoch 4/10\n",
      "16357/16357 [==============================] - 10s - loss: 3.8343 - main_out_loss: 1.8382 - aux_out_loss: 1.9961    \n",
      "Epoch 5/10\n",
      "16357/16357 [==============================] - 10s - loss: 3.7829 - main_out_loss: 1.8070 - aux_out_loss: 1.9760    \n",
      "Epoch 6/10\n",
      "16357/16357 [==============================] - 10s - loss: 3.7285 - main_out_loss: 1.7661 - aux_out_loss: 1.9624    \n",
      "Epoch 7/10\n",
      "16357/16357 [==============================] - 10s - loss: 3.6904 - main_out_loss: 1.7437 - aux_out_loss: 1.9468    \n",
      "Epoch 8/10\n",
      "16357/16357 [==============================] - 10s - loss: 3.6484 - main_out_loss: 1.7194 - aux_out_loss: 1.9291    \n",
      "Epoch 9/10\n",
      "16357/16357 [==============================] - 10s - loss: 3.6086 - main_out_loss: 1.6928 - aux_out_loss: 1.9158    \n",
      "Epoch 10/10\n",
      "16357/16357 [==============================] - 10s - loss: 3.5816 - main_out_loss: 1.6763 - aux_out_loss: 1.9053    \n",
      "iteration 28, author_id: 28\n",
      "Epoch 1/10\n",
      "16490/16490 [==============================] - 14s - loss: 4.3153 - main_out_loss: 2.1491 - aux_out_loss: 2.1662    \n",
      "Epoch 2/10\n",
      "16490/16490 [==============================] - 10s - loss: 4.1663 - main_out_loss: 2.0487 - aux_out_loss: 2.1176    \n",
      "Epoch 3/10\n",
      "16490/16490 [==============================] - 10s - loss: 4.0622 - main_out_loss: 1.9760 - aux_out_loss: 2.0862    \n",
      "Epoch 4/10\n",
      "16490/16490 [==============================] - 10s - loss: 3.9837 - main_out_loss: 1.9199 - aux_out_loss: 2.0637    \n",
      "Epoch 5/10\n",
      "16490/16490 [==============================] - 10s - loss: 3.9176 - main_out_loss: 1.8771 - aux_out_loss: 2.0406    \n",
      "Epoch 6/10\n",
      "16490/16490 [==============================] - 10s - loss: 3.8634 - main_out_loss: 1.8406 - aux_out_loss: 2.0228    \n",
      "Epoch 7/10\n",
      "16490/16490 [==============================] - 10s - loss: 3.8275 - main_out_loss: 1.8200 - aux_out_loss: 2.0075    \n",
      "Epoch 8/10\n",
      "16490/16490 [==============================] - 10s - loss: 3.7747 - main_out_loss: 1.7848 - aux_out_loss: 1.9899    \n",
      "Epoch 9/10\n",
      "16490/16490 [==============================] - 10s - loss: 3.7484 - main_out_loss: 1.7688 - aux_out_loss: 1.9797    \n",
      "Epoch 10/10\n",
      "16490/16490 [==============================] - 10s - loss: 3.7093 - main_out_loss: 1.7428 - aux_out_loss: 1.9665    \n",
      "iteration 29, author_id: 29\n",
      "Epoch 1/10\n",
      "16565/16565 [==============================] - 14s - loss: 4.1819 - main_out_loss: 2.0596 - aux_out_loss: 2.1223    \n",
      "Epoch 2/10\n",
      "16565/16565 [==============================] - 10s - loss: 4.0321 - main_out_loss: 1.9592 - aux_out_loss: 2.0728    \n",
      "Epoch 3/10\n",
      "16565/16565 [==============================] - 10s - loss: 3.9246 - main_out_loss: 1.8880 - aux_out_loss: 2.0366    \n",
      "Epoch 4/10\n",
      "16565/16565 [==============================] - 10s - loss: 3.8606 - main_out_loss: 1.8448 - aux_out_loss: 2.0158    \n",
      "Epoch 5/10\n",
      "16565/16565 [==============================] - 10s - loss: 3.7968 - main_out_loss: 1.8026 - aux_out_loss: 1.9943    \n",
      "Epoch 6/10\n",
      "16565/16565 [==============================] - 10s - loss: 3.7465 - main_out_loss: 1.7667 - aux_out_loss: 1.9797    \n",
      "Epoch 7/10\n",
      "16565/16565 [==============================] - 10s - loss: 3.6915 - main_out_loss: 1.7310 - aux_out_loss: 1.9605    \n",
      "Epoch 8/10\n",
      "16565/16565 [==============================] - 10s - loss: 3.6593 - main_out_loss: 1.7109 - aux_out_loss: 1.9484    \n",
      "Epoch 9/10\n",
      "16565/16565 [==============================] - 10s - loss: 3.6346 - main_out_loss: 1.6946 - aux_out_loss: 1.9401    \n",
      "Epoch 10/10\n",
      "16565/16565 [==============================] - 10s - loss: 3.5969 - main_out_loss: 1.6733 - aux_out_loss: 1.9235    \n"
     ]
    }
   ],
   "source": [
    "author_models = []  # [(author_model, author_id), (author_model, author_id), ...] - ids are ints\n",
    "for i, train_text in enumerate(train_texts):\n",
    "    print(\"iteration {}, author_id: {}\".format(i, train_labels[i]))\n",
    "    ct = clean_text(train_text, charset)\n",
    "    am = get_model(modelfile, freeze=True)\n",
    "    am.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    X, y = vectorize(ct)\n",
    "    am.fit(X, [y, y], epochs=10, batch_size=128)\n",
    "    author_models.append((am, train_labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "1500\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "print(len(author_models))\n",
    "print(len(test_texts))\n",
    "print(len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182.57733333333334"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = [text.count(\" \") for text in test_texts]\n",
    "mean(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "285/285 [==============================] - 0s     \n",
      "285/285 [==============================] - 0s     \n",
      "285/285 [==============================] - 0s     \n",
      "285/285 [==============================] - 0s     \n",
      "285/285 [==============================] - 0s     \n",
      "285/285 [==============================] - 0s     \n",
      "285/285 [==============================] - 0s     \n",
      "285/285 [==============================] - 0s     \n",
      "285/285 [==============================] - 0s     \n",
      "285/285 [==============================] - 0s     \n",
      "285/285 [==============================] - 0s     \n",
      "285/285 [==============================] - 0s     \n",
      "285/285 [==============================] - 0s     \n",
      "285/285 [==============================] - 0s     \n",
      "285/285 [==============================] - 0s     \n",
      "285/285 [==============================] - 0s     \n",
      "285/285 [==============================] - 0s     \n",
      "285/285 [==============================] - 0s     \n",
      "285/285 [==============================] - 0s     \n",
      "285/285 [==============================] - 0s     \n",
      "285/285 [==============================] - 0s     \n",
      "285/285 [==============================] - 0s     \n",
      "285/285 [==============================] - 0s     \n",
      "285/285 [==============================] - 0s     \n",
      "285/285 [==============================] - 0s     \n",
      "285/285 [==============================] - 0s     \n",
      "285/285 [==============================] - 0s     \n",
      "285/285 [==============================] - 0s     \n",
      "285/285 [==============================] - 0s     \n",
      "285/285 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "287/287 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283/283 [==============================] - 0s     \n",
      "283/283 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/288 [==============================] - 0s     \n",
      "288/297 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "indicies = list(range(len(test_texts)))\n",
    "\n",
    "test_texts = np.array(test_texts)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "test_texts = test_texts[indicies]\n",
    "test_labels = test_labels[indicies]\n",
    "\n",
    "predictions = []\n",
    "for text in test_texts:\n",
    "    X, y = vectorize(clean_text(text, charset))\n",
    "    \n",
    "    losses = []\n",
    "    for am in author_models:\n",
    "        model = am[0]\n",
    "        label = am[1]\n",
    "        loss = model.evaluate(X, [y, y])\n",
    "        losses.append((loss[0], label))\n",
    "    predictions.append(losses)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_is = []\n",
    "for pred in predictions:\n",
    "    pred_i = [p[0] for p in pred]\n",
    "    pred_is.append(pred_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labs = [np.argmin(pred) for pred in pred_is]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53800000000000003"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_labels, pred_labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 100, 300)      25500       input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 100, 300)      0           embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)                (None, 96, 64)        96064       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)   (None, 24, 64)        0           conv1d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 256)           328704      max_pooling1d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 512)           131072      lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 512)           2048        dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 512)           0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 256)           131072      activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 256)           1024        dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 256)           0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 85)            21845       activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 85)            21845       lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "main_out (Activation)            (None, 85)            0           dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "aux_out (Activation)             (None, 85)            0           dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 759,174\n",
      "Trainable params: 43,690\n",
      "Non-trainable params: 715,484\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "test_author_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Model.evaluate of <keras.engine.training.Model object at 0x7f7457285b70>>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_author_model.evaluatei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
